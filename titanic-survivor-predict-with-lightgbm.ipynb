{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tusharaggarwal27/titanic-survivor-predict-with-lightgbm?scriptVersionId=124030852\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#F5DEB3;\n           font-size:170%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n<p style=\"padding: 10px;\n          text-align: center;\n          font-size:150%;\n          color:blue;\">\n          üö¢üõ≥Ô∏è((Titanic Survivor Predict with LightGBM))üö¢üõ≥Ô∏è\n            \n</p>\n<style>\n        h1{text-align: center;}\n</style>  \n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:cursive; font-size:18px; color:'darkcyan';\">I brewed this notebook from scratch, If this notebook helped, please consider upvoting and cite me if sharing ,Thank you!</p>\n\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:18px;border-radius:20px\">\n    <a href=\"https://www.linkedin.com/in/tusharaggarwalinseec/\" target=\"_blank\">Lets connect on LinkedIn!</a>\n    \n   </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:18px;border-radius:20px\">\n<a href=\"https://github.com/tushar2704\" target=\"_blank\">Follow me on Github too!</a> </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:18px;border-radius:20px\">\n    <a href=\"https://medium.com/@tushar_aggarwal\" target=\"_blank\">Also checkout my Medium posts!</a>\n    \n   </p>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" role=\"alert\" style=\"font-size:17px;border-radius:20px\">\n    <b>In this project, I made a model with high accuracy to predict the Titanic survivor with LightGBM,</b>\n    <br><br>\n    <b>The Challenge:\n        <br>\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.</b>\n    \n</div>\n<div class=\"alert alert-info\" role=\"alert\" style=\"font-size:15px;border-radius:20px\">\n    <b>Some things to note:</b>\n    <br><br>On April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n    <br><br>\n    In this challenge, i have to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n  \n</div>\n\n","metadata":{}},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Importing the required Libraries\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot","metadata":{"id":"tZo7QdC1WRho","execution":{"iopub.status.busy":"2023-01-14T10:28:50.108167Z","iopub.execute_input":"2023-01-14T10:28:50.109358Z","iopub.status.idle":"2023-01-14T10:28:54.688832Z","shell.execute_reply.started":"2023-01-14T10:28:50.109247Z","shell.execute_reply":"2023-01-14T10:28:54.68708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Reading the Dataset\n    \n   </p>","metadata":{"id":"he1t2mIUXI8p"}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')","metadata":{"id":"TJFqvU72XE8g","execution":{"iopub.status.busy":"2023-01-14T10:28:54.706667Z","iopub.execute_input":"2023-01-14T10:28:54.708415Z","iopub.status.idle":"2023-01-14T10:28:54.761787Z","shell.execute_reply.started":"2023-01-14T10:28:54.708351Z","shell.execute_reply":"2023-01-14T10:28:54.760449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">EDA for the Data\n    \n   </p>","metadata":{"id":"6v89Qs1nYC6n"}},{"cell_type":"code","source":"df_train.head(5)","metadata":{"id":"AmjhLW4_Xk6D","outputId":"f3cdb3c2-49a7-48d5-f8a7-e61d0dd592c5","execution":{"iopub.status.busy":"2023-01-14T10:28:54.768389Z","iopub.execute_input":"2023-01-14T10:28:54.772169Z","iopub.status.idle":"2023-01-14T10:28:54.814711Z","shell.execute_reply.started":"2023-01-14T10:28:54.772085Z","shell.execute_reply":"2023-01-14T10:28:54.813277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head(5)","metadata":{"id":"v2LglcJQYJtP","outputId":"78475e9c-d252-4af2-9db2-7e456e7c878e","execution":{"iopub.status.busy":"2023-01-14T10:28:54.824337Z","iopub.execute_input":"2023-01-14T10:28:54.828355Z","iopub.status.idle":"2023-01-14T10:28:54.865638Z","shell.execute_reply.started":"2023-01-14T10:28:54.828285Z","shell.execute_reply":"2023-01-14T10:28:54.862949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_submission.head(5)\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId.","metadata":{"id":"oA4j8UsLYLwe","outputId":"7a0b2d81-a443-450e-c662-81ccb4ea5387","execution":{"iopub.status.busy":"2023-01-14T10:28:54.86784Z","iopub.execute_input":"2023-01-14T10:28:54.868891Z","iopub.status.idle":"2023-01-14T10:28:54.887605Z","shell.execute_reply.started":"2023-01-14T10:28:54.868835Z","shell.execute_reply":"2023-01-14T10:28:54.886104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5)","metadata":{"id":"OSGSZb2iYQCg","outputId":"92930d0d-baf3-4c1d-d501-2d0c7ba4131b","execution":{"iopub.status.busy":"2023-01-14T10:28:54.890204Z","iopub.execute_input":"2023-01-14T10:28:54.89141Z","iopub.status.idle":"2023-01-14T10:28:54.934505Z","shell.execute_reply.started":"2023-01-14T10:28:54.891328Z","shell.execute_reply":"2023-01-14T10:28:54.932531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">EDA with Pairplot (for multiple pairwise bivariate distributions)\n    \n   </p>\n","metadata":{}},{"cell_type":"code","source":"# Let's analyze how the distribution is statistically through pair plots and several graphs.\nsns.pairplot(data = df_train)","metadata":{"id":"5yNtK3y8YTjU","outputId":"33073787-1c41-44a7-96e1-67fb8d526aa0","execution":{"iopub.status.busy":"2023-01-14T10:28:54.939617Z","iopub.execute_input":"2023-01-14T10:28:54.942129Z","iopub.status.idle":"2023-01-14T10:29:10.376122Z","shell.execute_reply.started":"2023-01-14T10:28:54.942053Z","shell.execute_reply":"2023-01-14T10:29:10.374934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">The first graph now is the result of heatmap analysis of data. The higher the correlation, the darker the color.\n    <br>The second graph graphed the null ratio.\n    \n   </p>","metadata":{}},{"cell_type":"code","source":"def analysis(data):\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90)","metadata":{"id":"n5LSfzZbYY_Y","execution":{"iopub.status.busy":"2023-01-14T10:29:10.37758Z","iopub.execute_input":"2023-01-14T10:29:10.379259Z","iopub.status.idle":"2023-01-14T10:29:10.389371Z","shell.execute_reply.started":"2023-01-14T10:29:10.379184Z","shell.execute_reply":"2023-01-14T10:29:10.387556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For df_train\nanalysis(df_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-14T10:29:10.392303Z","iopub.execute_input":"2023-01-14T10:29:10.39353Z","iopub.status.idle":"2023-01-14T10:29:11.393322Z","shell.execute_reply.started":"2023-01-14T10:29:10.393476Z","shell.execute_reply":"2023-01-14T10:29:11.391843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For df_test\nanalysis(df_test)","metadata":{"id":"bfBgZkeLYsl9","outputId":"e6942e39-f103-4443-8daf-545c4cf302da","execution":{"iopub.status.busy":"2023-01-14T10:29:11.398875Z","iopub.execute_input":"2023-01-14T10:29:11.400193Z","iopub.status.idle":"2023-01-14T10:29:12.590246Z","shell.execute_reply.started":"2023-01-14T10:29:11.400141Z","shell.execute_reply":"2023-01-14T10:29:12.58878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now using OLS Regression\n   </p>","metadata":{}},{"cell_type":"code","source":"fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4/ Adjust R-square 0.39 level could be predicted.","metadata":{"id":"fwGGai-oYubv","outputId":"9e1d1b80-67be-4607-8218-c3a4fec8cc08","execution":{"iopub.status.busy":"2023-01-14T10:29:12.592607Z","iopub.execute_input":"2023-01-14T10:29:12.593136Z","iopub.status.idle":"2023-01-14T10:29:12.6552Z","shell.execute_reply.started":"2023-01-14T10:29:12.59309Z","shell.execute_reply":"2023-01-14T10:29:12.653527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now numeric dtype Feature Enginearing\n   </p>\n","metadata":{}},{"cell_type":"code","source":"num_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\n\ndf_train[num_cols].describe()","metadata":{"id":"rvETL7EhY4HF","outputId":"4b8c87bc-c6c7-4369-86ae-326ff1f1839f","execution":{"iopub.status.busy":"2023-01-14T10:29:12.65739Z","iopub.execute_input":"2023-01-14T10:29:12.658652Z","iopub.status.idle":"2023-01-14T10:29:12.707217Z","shell.execute_reply.started":"2023-01-14T10:29:12.658608Z","shell.execute_reply":"2023-01-14T10:29:12.705096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now, finfind correlation for df_train\ndf_train.corr(method='pearson')","metadata":{"id":"-whvi1noY73u","outputId":"8d992389-82c1-4bd0-f6a5-4949b22b38e4","execution":{"iopub.status.busy":"2023-01-14T10:29:12.709783Z","iopub.execute_input":"2023-01-14T10:29:12.710341Z","iopub.status.idle":"2023-01-14T10:29:12.735137Z","shell.execute_reply.started":"2023-01-14T10:29:12.710293Z","shell.execute_reply":"2023-01-14T10:29:12.73252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, checking for duplicate values in the data\n   </p>\n","metadata":{}},{"cell_type":"code","source":"#Checking metadata for df_train\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2023-01-14T10:29:12.737128Z","iopub.execute_input":"2023-01-14T10:29:12.737927Z","iopub.status.idle":"2023-01-14T10:29:12.763209Z","shell.execute_reply.started":"2023-01-14T10:29:12.737875Z","shell.execute_reply":"2023-01-14T10:29:12.76152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping duplicates\ndf_train=df_train.drop_duplicates()","metadata":{"id":"UwXpijHZY_Yh","execution":{"iopub.status.busy":"2023-01-14T10:29:12.76649Z","iopub.execute_input":"2023-01-14T10:29:12.767202Z","iopub.status.idle":"2023-01-14T10:29:12.781904Z","shell.execute_reply.started":"2023-01-14T10:29:12.767121Z","shell.execute_reply":"2023-01-14T10:29:12.780195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for difference\ndf_train.info()","metadata":{"id":"ZJycFug2ZCF9","outputId":"5192159b-63dc-437b-e474-6dd7c86b0491","execution":{"iopub.status.busy":"2023-01-14T10:29:12.784611Z","iopub.execute_input":"2023-01-14T10:29:12.785198Z","iopub.status.idle":"2023-01-14T10:29:12.804373Z","shell.execute_reply.started":"2023-01-14T10:29:12.785146Z","shell.execute_reply":"2023-01-14T10:29:12.802308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, checking for skewness and kurtosis\n   </p>\n‚Äã","metadata":{}},{"cell_type":"code","source":"# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show()","metadata":{"id":"5flmarDoZDcr","outputId":"01fb4c89-947a-4709-a682-68b4b0de38a6","execution":{"iopub.status.busy":"2023-01-14T10:29:12.806501Z","iopub.execute_input":"2023-01-14T10:29:12.808275Z","iopub.status.idle":"2023-01-14T10:29:13.353493Z","shell.execute_reply.started":"2023-01-14T10:29:12.808215Z","shell.execute_reply":"2023-01-14T10:29:13.352063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Countplots\n   </p>\n","metadata":{}},{"cell_type":"code","source":"def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)","metadata":{"id":"fBwLQJLfZGb6","execution":{"iopub.status.busy":"2023-01-14T10:29:13.355573Z","iopub.execute_input":"2023-01-14T10:29:13.357399Z","iopub.status.idle":"2023-01-14T10:29:13.366288Z","shell.execute_reply.started":"2023-01-14T10:29:13.35734Z","shell.execute_reply":"2023-01-14T10:29:13.364766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Columns with more than 20 variables in the column are as shown below.The distribution of numbers of columns and survivors with less than 20 variables is as shown in the graph.')\nprint(over_column_name)","metadata":{"id":"ZSFc58dcZIQn","outputId":"46d4cf2a-308a-44a6-b859-5c3b53ae04ce","execution":{"iopub.status.busy":"2023-01-14T10:29:13.36875Z","iopub.execute_input":"2023-01-14T10:29:13.369391Z","iopub.status.idle":"2023-01-14T10:29:14.719535Z","shell.execute_reply.started":"2023-01-14T10:29:13.369338Z","shell.execute_reply":"2023-01-14T10:29:14.71807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout()","metadata":{"id":"DKxBbPNiZOyx","outputId":"948ca83d-e883-45b3-d024-916776c90a87","execution":{"iopub.status.busy":"2023-01-14T10:29:14.722391Z","iopub.execute_input":"2023-01-14T10:29:14.723243Z","iopub.status.idle":"2023-01-14T10:29:25.225201Z","shell.execute_reply.started":"2023-01-14T10:29:14.723191Z","shell.execute_reply":"2023-01-14T10:29:25.22379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, For Category columns\n   </p>","metadata":{}},{"cell_type":"code","source":"cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout()","metadata":{"id":"qPThZxsXZR7j","outputId":"3fa5e9fc-446f-4018-f538-edb3cf724214","execution":{"iopub.status.busy":"2023-01-14T10:29:25.230048Z","iopub.execute_input":"2023-01-14T10:29:25.235165Z","iopub.status.idle":"2023-01-14T10:29:50.705016Z","shell.execute_reply.started":"2023-01-14T10:29:25.235098Z","shell.execute_reply":"2023-01-14T10:29:50.703736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Checking for missing values and dropping them\n   </p>","metadata":{}},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"id":"vWIZqZcwZU0Y","outputId":"368230e9-acd6-46f0-d33b-5eb1588eac89","execution":{"iopub.status.busy":"2023-01-14T10:29:50.706668Z","iopub.execute_input":"2023-01-14T10:29:50.707721Z","iopub.status.idle":"2023-01-14T10:29:50.723981Z","shell.execute_reply.started":"2023-01-14T10:29:50.707669Z","shell.execute_reply":"2023-01-14T10:29:50.722225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping missing values\ndf_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1)","metadata":{"id":"VLsuQXhpZaSn","execution":{"iopub.status.busy":"2023-01-14T10:29:50.725868Z","iopub.execute_input":"2023-01-14T10:29:50.727309Z","iopub.status.idle":"2023-01-14T10:29:50.738832Z","shell.execute_reply.started":"2023-01-14T10:29:50.727251Z","shell.execute_reply":"2023-01-14T10:29:50.737449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cabin It's a waste to throw away all the information, so I'm thinking of using the number of characters as a variable.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0)","metadata":{"id":"W2msLs_cZc6H","execution":{"iopub.status.busy":"2023-01-14T10:29:50.740612Z","iopub.execute_input":"2023-01-14T10:29:50.742705Z","iopub.status.idle":"2023-01-14T10:29:50.757331Z","shell.execute_reply.started":"2023-01-14T10:29:50.742643Z","shell.execute_reply":"2023-01-14T10:29:50.755871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1)","metadata":{"id":"TSUSh0hNZil-","execution":{"iopub.status.busy":"2023-01-14T10:29:50.759077Z","iopub.execute_input":"2023-01-14T10:29:50.759939Z","iopub.status.idle":"2023-01-14T10:29:50.774267Z","shell.execute_reply.started":"2023-01-14T10:29:50.75989Z","shell.execute_reply":"2023-01-14T10:29:50.773012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test)","metadata":{"id":"CzEth_UkZkcV","execution":{"iopub.status.busy":"2023-01-14T10:29:50.776497Z","iopub.execute_input":"2023-01-14T10:29:50.777072Z","iopub.status.idle":"2023-01-14T10:29:50.809626Z","shell.execute_reply.started":"2023-01-14T10:29:50.777024Z","shell.execute_reply":"2023-01-14T10:29:50.807771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()\ndf_test.info()","metadata":{"id":"b7j10UquZl39","outputId":"329eeac8-471c-4ca4-c90c-0312732f1638","execution":{"iopub.status.busy":"2023-01-14T10:29:50.811721Z","iopub.execute_input":"2023-01-14T10:29:50.812812Z","iopub.status.idle":"2023-01-14T10:29:50.850214Z","shell.execute_reply.started":"2023-01-14T10:29:50.812755Z","shell.execute_reply":"2023-01-14T10:29:50.848778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"id":"q-N_2oZGZnDW","outputId":"a5735a61-7964-40ec-fee2-8d3eb704226b","execution":{"iopub.status.busy":"2023-01-14T10:29:50.857544Z","iopub.execute_input":"2023-01-14T10:29:50.858558Z","iopub.status.idle":"2023-01-14T10:29:50.880722Z","shell.execute_reply.started":"2023-01-14T10:29:50.858517Z","shell.execute_reply":"2023-01-14T10:29:50.878899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Building the Model - LGBMClassifier\n   </p>","metadata":{"id":"DbEgPQx5ZwRb"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nrandom_state_val =42 #Choosing this value\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)","metadata":{"id":"dz01XCn4ZpFC","execution":{"iopub.status.busy":"2023-01-14T10:29:50.882682Z","iopub.execute_input":"2023-01-14T10:29:50.884074Z","iopub.status.idle":"2023-01-14T10:29:50.896207Z","shell.execute_reply.started":"2023-01-14T10:29:50.883974Z","shell.execute_reply":"2023-01-14T10:29:50.894388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining variables\ndrop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm])","metadata":{"id":"DanXiqy2Z-sb","execution":{"iopub.status.busy":"2023-01-14T10:29:50.898785Z","iopub.execute_input":"2023-01-14T10:29:50.900167Z","iopub.status.idle":"2023-01-14T10:29:50.915468Z","shell.execute_reply.started":"2023-01-14T10:29:50.900107Z","shell.execute_reply":"2023-01-14T10:29:50.914038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now creating LGBMClassifier and adjusting hyperparas\nLGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)","metadata":{"id":"8PmonRRBaAoQ","execution":{"iopub.status.busy":"2023-01-14T10:29:50.918319Z","iopub.execute_input":"2023-01-14T10:29:50.919505Z","iopub.status.idle":"2023-01-14T10:29:50.929667Z","shell.execute_reply.started":"2023-01-14T10:29:50.919449Z","shell.execute_reply":"2023-01-14T10:29:50.927663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting the model on LGBMClassifier\nstart = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start","metadata":{"id":"74vW8MSFaCvV","outputId":"53787f25-8e40-4e12-bbfe-170625cf7cf9","execution":{"iopub.status.busy":"2023-01-14T10:29:50.931972Z","iopub.execute_input":"2023-01-14T10:29:50.933034Z","iopub.status.idle":"2023-01-14T10:29:51.35452Z","shell.execute_reply.started":"2023-01-14T10:29:50.932954Z","shell.execute_reply":"2023-01-14T10:29:51.353383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Checking the variables that have a major impact, and graphing them.\n   </p>","metadata":{}},{"cell_type":"code","source":"feature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\nfeature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\nplt.savefig('lightGBM_ Importances.png')","metadata":{"id":"znwBFXuraEgz","outputId":"80fd783a-6c8a-49aa-a9ec-011403bdaf52","execution":{"iopub.status.busy":"2023-01-14T10:29:51.358576Z","iopub.execute_input":"2023-01-14T10:29:51.362913Z","iopub.status.idle":"2023-01-14T10:29:52.161334Z","shell.execute_reply.started":"2023-01-14T10:29:51.362856Z","shell.execute_reply":"2023-01-14T10:29:52.15974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Best Accuracy-SCORE =%f, Threshold=%f'%(max_accuracy, opt_threshold))\nprint('Threshold Setup complete')","metadata":{"id":"4_TgSJg-aKjV","outputId":"ba84e386-0f46-4fc9-9b08-d0cc591245cf","execution":{"iopub.status.busy":"2023-01-14T10:29:52.163774Z","iopub.execute_input":"2023-01-14T10:29:52.164375Z","iopub.status.idle":"2023-01-14T10:29:52.445892Z","shell.execute_reply.started":"2023-01-14T10:29:52.164324Z","shell.execute_reply":"2023-01-14T10:29:52.44441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Analyzing the model results,\n    <br><br>\nI tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model.\n   </p>\n","metadata":{"id":"W7CV-jXgafdE"}},{"cell_type":"code","source":"#Predicting on train\npredict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()","metadata":{"id":"a6paHAwjaYMJ","execution":{"iopub.status.busy":"2023-01-14T10:29:52.448024Z","iopub.execute_input":"2023-01-14T10:29:52.44894Z","iopub.status.idle":"2023-01-14T10:29:52.483148Z","shell.execute_reply.started":"2023-01-14T10:29:52.448871Z","shell.execute_reply":"2023-01-14T10:29:52.481668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))","metadata":{"id":"lx2NvApfatMI","outputId":"b14baeff-626c-410a-aac2-7545cc1c2f19","execution":{"iopub.status.busy":"2023-01-14T10:29:52.485209Z","iopub.execute_input":"2023-01-14T10:29:52.486109Z","iopub.status.idle":"2023-01-14T10:29:52.515065Z","shell.execute_reply.started":"2023-01-14T10:29:52.486044Z","shell.execute_reply":"2023-01-14T10:29:52.513478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting ROC Curve\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"M2nPXnmZavVc","outputId":"29ce8cb0-c371-4973-bce7-6d8081647dcb","execution":{"iopub.status.busy":"2023-01-14T10:29:52.517177Z","iopub.execute_input":"2023-01-14T10:29:52.518123Z","iopub.status.idle":"2023-01-14T10:29:52.789451Z","shell.execute_reply.started":"2023-01-14T10:29:52.518067Z","shell.execute_reply":"2023-01-14T10:29:52.788159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">First, Model Metric Sumamry\n   \n   </p>","metadata":{}},{"cell_type":"code","source":"Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"id":"T63lNq06axUy","outputId":"6edd4c5c-a7db-440a-dadd-aa2bbe757cca","execution":{"iopub.status.busy":"2023-01-14T10:29:52.791093Z","iopub.execute_input":"2023-01-14T10:29:52.791586Z","iopub.status.idle":"2023-01-14T10:29:52.805111Z","shell.execute_reply.started":"2023-01-14T10:29:52.791538Z","shell.execute_reply":"2023-01-14T10:29:52.803715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting on Validation data\npredict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"Second, Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"id":"FiN3F6TRazdH","outputId":"e818fce2-1c8a-49ac-ce60-296a5a545214","execution":{"iopub.status.busy":"2023-01-14T10:29:52.806577Z","iopub.execute_input":"2023-01-14T10:29:52.807653Z","iopub.status.idle":"2023-01-14T10:29:53.108957Z","shell.execute_reply.started":"2023-01-14T10:29:52.807605Z","shell.execute_reply":"2023-01-14T10:29:53.107574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"Third, Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"id":"1i1UXQ_sa3tM","outputId":"8d0f57c3-0939-4725-9883-c2e76fb833a1","execution":{"iopub.status.busy":"2023-01-14T10:29:53.110869Z","iopub.execute_input":"2023-01-14T10:29:53.111983Z","iopub.status.idle":"2023-01-14T10:29:53.425868Z","shell.execute_reply.started":"2023-01-14T10:29:53.111933Z","shell.execute_reply":"2023-01-14T10:29:53.424512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Preparing submission materials\n   \n   </p>","metadata":{}},{"cell_type":"code","source":"test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"id":"3lOhyWTea8C7","execution":{"iopub.status.busy":"2023-01-14T10:29:53.427705Z","iopub.execute_input":"2023-01-14T10:29:53.429331Z","iopub.status.idle":"2023-01-14T10:29:53.452466Z","shell.execute_reply.started":"2023-01-14T10:29:53.429278Z","shell.execute_reply":"2023-01-14T10:29:53.450813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:17px;border-radius:20px\">Now, Submitted the csv for the competition","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:#a5d610;\n           font-size:120%;\n           font-family:Helvetica, Sans-Serif;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n          text-align: center;\n          color:black;\">\nWe are doing something right here, üòÄ, as after submission rank I got is under Top 12% üòÄ!!, follow me for more optimization on this and better results\n</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-family:cursive; font-size:18px; color:'darkcyan';\">I brewed this notebook from scratch, If this notebook helped, please consider upvoting and cite me if sharing ,Thank you!</p>\n\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:18px;border-radius:20px\">\n    <a href=\"https://www.linkedin.com/in/tusharaggarwalinseec/\" target=\"_blank\">Lets connect on LinkedIn!</a>\n    \n   </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:18px;border-radius:20px\">\n<a href=\"https://github.com/tushar2704\" target=\"_blank\">Follow me on Github too!</a> </p>\n<p style=\"width: 700px;padding: 20px;background: papayawhip;border-radius:10px;font-size:18px;border-radius:20px\">\n    <a href=\"https://medium.com/@tushar_aggarwal\" target=\"_blank\">Also checkout my Medium posts!</a>\n    \n   </p>","metadata":{}}]}